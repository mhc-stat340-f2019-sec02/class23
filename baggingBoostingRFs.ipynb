{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging, Boosting, and Random Forests\n",
    "\n",
    "Decision trees have many advantages.\n",
    "They are easy to interpret.\n",
    "To make a prediction, you only need to follow a set of rules. \n",
    "Predictions are also data-driven, not having to follow a more structured linear pattern like the past model we studied.\n",
    "Regression trees also have two big disadvantages: (i) they typically have poor performance compared to other regression models, and (ii) suffer from high variance.\n",
    "\n",
    "## Goal of ensemble\n",
    "\n",
    "The goal of an ensemble model is to combine many weak predictors, and in doing so, build a model that has lower variance and bias.\n",
    "This phenomena occurs in simple statistics.\n",
    "Given a sample of data $Y_{1},Y_{2},\\cdots,Y_{n}$ the average $\\bar{Y}$ has a Normal distribution with variance $\\sigma^{2}/n$. \n",
    "The average lowers the variance.  \n",
    "A single regression tree tends to have high variance. \n",
    "Combining many different regression trees, in an ensemble, attempts to lower the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging for a continuous target\n",
    "\n",
    "\n",
    "### Bootstrap\n",
    "\n",
    "### Averaging\n",
    "\n",
    "\n",
    "## Bagging for a categorical target\n",
    "\n",
    "### Majority Vote\n",
    "\n",
    "\n",
    "## Measuring out of sample error\n",
    "\n",
    "\n",
    "\n",
    "## Random forests"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
